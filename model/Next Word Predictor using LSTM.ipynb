{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "xXqNpJCx8yVK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "8WduccH--7h8"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_clean_dialogues(filepath, max_lines=20000):\n",
    "    dialogues = []\n",
    "    with open(filepath, encoding='utf-8', errors='ignore') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            if idx >= max_lines:\n",
    "                break\n",
    "            parts = line.strip().split(\" +++$+++ \")\n",
    "            if len(parts) == 5:\n",
    "                text = parts[4].lower()\n",
    "                text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # remove punctuation\n",
    "                tokens = text.split()\n",
    "                if len(tokens) > 1:\n",
    "                    dialogues.append(tokens)\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pLKXYPm-_LGn",
    "outputId": "a43a21a6-830e-4392-b255-62e08b6cb7a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 18359 cleaned dialogues\n",
      "Sample: [['they', 'do', 'not'], ['they', 'do', 'to'], ['i', 'hope', 'so'], ['she', 'okay'], ['lets', 'go']]\n"
     ]
    }
   ],
   "source": [
    "file_path = \"movie_lines.txt\"\n",
    "dialogues = extract_clean_dialogues(file_path)\n",
    "print(f\"Loaded {len(dialogues)} cleaned dialogues\")\n",
    "print(\"Sample:\", dialogues[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "IqytIhdLjtar"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def prepare_sequences(token_lists, seq_length=5):\n",
    "    # Flatten the list of tokens\n",
    "    all_tokens = [word for line in token_lists for word in line]\n",
    "    # ['i', 'am', 'happy', 'you', 'are', 'great']\n",
    "\n",
    "    # Create vocabulary\n",
    "    vocab = sorted(set(all_tokens))\n",
    "    # ['am', 'are', 'great', 'happy', 'i', 'you']\n",
    "\n",
    "    word2idx = {word: idx+1 for idx, word in enumerate(vocab)}  # reserve 0 for padding\n",
    "    idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "    #word2idx = {'am':1, 'are':2, 'great':3, 'happy':4, 'i':5, 'you':6}\n",
    "    #idx2word = {1:'am', 2:'are', 3:'great', 4:'happy', 5:'i', 6:'you'}\n",
    "\n",
    "    # Generate sequences\n",
    "    sequences = []\n",
    "    for i in range(seq_length, len(all_tokens)):\n",
    "        seq = all_tokens[i-seq_length:i+1]  # n words + 1 target\n",
    "        sequences.append([word2idx[word] for word in seq])\n",
    "\n",
    "   #i = 3 → ['i', 'am', 'happy', 'you'] → X: ['i', 'am', 'happy'], y: 'you'\n",
    "   #i = 4 → ['am', 'happy', 'you', 'are'] → X: ['am', 'happy', 'you'], y: 'are'\n",
    "   #i = 5 → ['happy', 'you', 'are', 'great'] → X: ['happy', 'you', 'are'], y: 'great'\n",
    "\n",
    "    sequences = np.array(sequences)\n",
    "    X = sequences[:, :-1]\n",
    "    y = sequences[:, -1]\n",
    "\n",
    "    '''sequences = [\n",
    "    [5, 1, 4, 6],   # 'i', 'am', 'happy', 'you'\n",
    "    [1, 4, 6, 2],   # 'am', 'happy', 'you', 'are'\n",
    "    [4, 6, 2, 3]    # 'happy', 'you', 'are', 'great'\n",
    "]\n",
    "Then:\n",
    "\n",
    "    X = sequences[:, :-1]  # all except last token → input\n",
    "    y = sequences[:, -1]   # last token → target\n",
    "\n",
    "    # X = [\n",
    "    #   [5, 1, 4],  # i am happy\n",
    "    #   [1, 4, 6],  # am happy you\n",
    "    #   [4, 6, 2]   # happy you are\n",
    "    # ]\n",
    "\n",
    "    # y = [6, 2, 3]  # you, are, great'''\n",
    "    return X, y, word2idx, idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save word2idx\n",
    "with open(\"word2idx.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word2idx, f)\n",
    "\n",
    "# Save idx2word\n",
    "with open(\"idx2word.pkl\", \"wb\") as f:\n",
    "    pickle.dump(idx2word, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rFFlVv72j-dS",
    "outputId": "33c4fad4-e56d-411e-e4ed-62437fcd1ce6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence (X[0]): [11425  3298  7693 11425  3298]\n",
      "Target word index (y[0]): 11563\n",
      "Target word (decoded): to\n",
      "Vocabulary size: 12916\n"
     ]
    }
   ],
   "source": [
    "X, y, word2idx, idx2word = prepare_sequences(dialogues, seq_length=5)\n",
    "\n",
    "print(\"Input sequence (X[0]):\", X[0])\n",
    "print(\"Target word index (y[0]):\", y[0])\n",
    "print(\"Target word (decoded):\", idx2word[y[0]])\n",
    "print(\"Vocabulary size:\", len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "AJC4dF7GlELT"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(word2idx) + 1  # +1 for padding (index 0)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G3Urv7j4lY6l",
    "outputId": "a35a61c8-9325-43e3-9a12-83bd35e51565"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=seq_length))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(vocab_size, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "CPW6_0cclyIe"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uHHoY3o6l5Wo",
    "outputId": "199e74fa-a256-4255-b1c0-bb1f1cd37024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 6.6589 - accuracy: 0.0437\n",
      "Epoch 2/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 6.0934 - accuracy: 0.0725\n",
      "Epoch 3/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 5.7592 - accuracy: 0.1014\n",
      "Epoch 4/100\n",
      "1571/1571 [==============================] - 33s 21ms/step - loss: 5.5156 - accuracy: 0.1153\n",
      "Epoch 5/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 5.3029 - accuracy: 0.1251\n",
      "Epoch 6/100\n",
      "1571/1571 [==============================] - 35s 23ms/step - loss: 5.1012 - accuracy: 0.1341\n",
      "Epoch 7/100\n",
      "1571/1571 [==============================] - 40s 25ms/step - loss: 4.9074 - accuracy: 0.1437\n",
      "Epoch 8/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 4.7230 - accuracy: 0.1559\n",
      "Epoch 9/100\n",
      "1571/1571 [==============================] - 41s 26ms/step - loss: 4.5480 - accuracy: 0.1693\n",
      "Epoch 10/100\n",
      "1571/1571 [==============================] - 37s 24ms/step - loss: 4.3819 - accuracy: 0.1851\n",
      "Epoch 11/100\n",
      "1571/1571 [==============================] - 40s 26ms/step - loss: 4.2264 - accuracy: 0.2028\n",
      "Epoch 12/100\n",
      "1571/1571 [==============================] - 44s 28ms/step - loss: 4.0815 - accuracy: 0.2204\n",
      "Epoch 13/100\n",
      "1571/1571 [==============================] - 53s 34ms/step - loss: 3.9463 - accuracy: 0.2376\n",
      "Epoch 14/100\n",
      "1571/1571 [==============================] - 56s 36ms/step - loss: 3.8205 - accuracy: 0.2538\n",
      "Epoch 15/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 3.7018 - accuracy: 0.2715\n",
      "Epoch 16/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 3.5906 - accuracy: 0.2873\n",
      "Epoch 17/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 3.4840 - accuracy: 0.3038\n",
      "Epoch 18/100\n",
      "1571/1571 [==============================] - 36s 23ms/step - loss: 3.3835 - accuracy: 0.3197\n",
      "Epoch 19/100\n",
      "1571/1571 [==============================] - 41s 26ms/step - loss: 3.2879 - accuracy: 0.3346\n",
      "Epoch 20/100\n",
      "1571/1571 [==============================] - 37s 23ms/step - loss: 3.1982 - accuracy: 0.3495\n",
      "Epoch 21/100\n",
      "1571/1571 [==============================] - 34s 21ms/step - loss: 3.1112 - accuracy: 0.3634\n",
      "Epoch 22/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 3.0293 - accuracy: 0.3781\n",
      "Epoch 23/100\n",
      "1571/1571 [==============================] - 51s 32ms/step - loss: 2.9513 - accuracy: 0.3928\n",
      "Epoch 24/100\n",
      "1571/1571 [==============================] - 38s 24ms/step - loss: 2.8776 - accuracy: 0.4049\n",
      "Epoch 25/100\n",
      "1571/1571 [==============================] - 39s 25ms/step - loss: 2.8077 - accuracy: 0.4178\n",
      "Epoch 26/100\n",
      "1571/1571 [==============================] - 38s 24ms/step - loss: 2.7403 - accuracy: 0.4302\n",
      "Epoch 27/100\n",
      "1571/1571 [==============================] - 37s 23ms/step - loss: 2.6778 - accuracy: 0.4418\n",
      "Epoch 28/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 2.6172 - accuracy: 0.4527\n",
      "Epoch 29/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 2.5594 - accuracy: 0.4638\n",
      "Epoch 30/100\n",
      "1571/1571 [==============================] - 32s 21ms/step - loss: 2.5049 - accuracy: 0.4735\n",
      "Epoch 31/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 2.4538 - accuracy: 0.4824\n",
      "Epoch 32/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 2.4040 - accuracy: 0.4929\n",
      "Epoch 33/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 2.3569 - accuracy: 0.5013\n",
      "Epoch 34/100\n",
      "1571/1571 [==============================] - 38s 24ms/step - loss: 2.3117 - accuracy: 0.5102\n",
      "Epoch 35/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 2.2684 - accuracy: 0.5192\n",
      "Epoch 36/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 2.2284 - accuracy: 0.5256\n",
      "Epoch 37/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 2.1897 - accuracy: 0.5319\n",
      "Epoch 38/100\n",
      "1571/1571 [==============================] - 39s 25ms/step - loss: 2.1516 - accuracy: 0.5399\n",
      "Epoch 39/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 2.1160 - accuracy: 0.5472\n",
      "Epoch 40/100\n",
      "1571/1571 [==============================] - 34s 21ms/step - loss: 2.0826 - accuracy: 0.5532\n",
      "Epoch 41/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 2.0500 - accuracy: 0.5600\n",
      "Epoch 42/100\n",
      "1571/1571 [==============================] - 35s 23ms/step - loss: 2.0191 - accuracy: 0.5658\n",
      "Epoch 43/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.9887 - accuracy: 0.5716\n",
      "Epoch 44/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.9597 - accuracy: 0.5776\n",
      "Epoch 45/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.9324 - accuracy: 0.5820\n",
      "Epoch 46/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.9050 - accuracy: 0.5876\n",
      "Epoch 47/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.8803 - accuracy: 0.5928\n",
      "Epoch 48/100\n",
      "1571/1571 [==============================] - 30s 19ms/step - loss: 1.8559 - accuracy: 0.5973\n",
      "Epoch 49/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.8314 - accuracy: 0.6015\n",
      "Epoch 50/100\n",
      "1571/1571 [==============================] - 63s 40ms/step - loss: 1.8101 - accuracy: 0.6062\n",
      "Epoch 51/100\n",
      "1571/1571 [==============================] - 68s 43ms/step - loss: 1.7867 - accuracy: 0.6113\n",
      "Epoch 52/100\n",
      "1571/1571 [==============================] - 63s 40ms/step - loss: 1.7671 - accuracy: 0.6140\n",
      "Epoch 53/100\n",
      "1571/1571 [==============================] - 64s 41ms/step - loss: 1.7454 - accuracy: 0.6191\n",
      "Epoch 54/100\n",
      "1571/1571 [==============================] - 51s 32ms/step - loss: 1.7277 - accuracy: 0.6220\n",
      "Epoch 55/100\n",
      "1571/1571 [==============================] - 46s 30ms/step - loss: 1.7075 - accuracy: 0.6260\n",
      "Epoch 56/100\n",
      "1571/1571 [==============================] - 50s 32ms/step - loss: 1.6884 - accuracy: 0.6298\n",
      "Epoch 57/100\n",
      "1571/1571 [==============================] - 65s 42ms/step - loss: 1.6720 - accuracy: 0.6330\n",
      "Epoch 58/100\n",
      "1571/1571 [==============================] - 64s 41ms/step - loss: 1.6546 - accuracy: 0.6362\n",
      "Epoch 59/100\n",
      "1571/1571 [==============================] - 49s 31ms/step - loss: 1.6381 - accuracy: 0.6400\n",
      "Epoch 60/100\n",
      "1571/1571 [==============================] - 47s 30ms/step - loss: 1.6217 - accuracy: 0.6420\n",
      "Epoch 61/100\n",
      "1571/1571 [==============================] - 47s 30ms/step - loss: 1.6060 - accuracy: 0.6457\n",
      "Epoch 62/100\n",
      "1571/1571 [==============================] - 46s 29ms/step - loss: 1.5896 - accuracy: 0.6490\n",
      "Epoch 63/100\n",
      "1571/1571 [==============================] - 46s 29ms/step - loss: 1.5770 - accuracy: 0.6515\n",
      "Epoch 64/100\n",
      "1571/1571 [==============================] - 49s 31ms/step - loss: 1.5605 - accuracy: 0.6552\n",
      "Epoch 65/100\n",
      "1571/1571 [==============================] - 47s 30ms/step - loss: 1.5485 - accuracy: 0.6574\n",
      "Epoch 66/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 1.5337 - accuracy: 0.6608\n",
      "Epoch 67/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.5214 - accuracy: 0.6627\n",
      "Epoch 68/100\n",
      "1571/1571 [==============================] - 32s 21ms/step - loss: 1.5085 - accuracy: 0.6645\n",
      "Epoch 69/100\n",
      "1571/1571 [==============================] - 39s 25ms/step - loss: 1.4960 - accuracy: 0.6669\n",
      "Epoch 70/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.4855 - accuracy: 0.6702\n",
      "Epoch 71/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.4727 - accuracy: 0.6720\n",
      "Epoch 72/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.4590 - accuracy: 0.6752\n",
      "Epoch 73/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.4505 - accuracy: 0.6763\n",
      "Epoch 74/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.4393 - accuracy: 0.6790\n",
      "Epoch 75/100\n",
      "1571/1571 [==============================] - 33s 21ms/step - loss: 1.4292 - accuracy: 0.6804\n",
      "Epoch 76/100\n",
      "1571/1571 [==============================] - 34s 21ms/step - loss: 1.4188 - accuracy: 0.6829\n",
      "Epoch 77/100\n",
      "1571/1571 [==============================] - 32s 21ms/step - loss: 1.4090 - accuracy: 0.6841\n",
      "Epoch 78/100\n",
      "1571/1571 [==============================] - 33s 21ms/step - loss: 1.3989 - accuracy: 0.6863\n",
      "Epoch 79/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.3888 - accuracy: 0.6877\n",
      "Epoch 80/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.3803 - accuracy: 0.6895\n",
      "Epoch 81/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.3698 - accuracy: 0.6925\n",
      "Epoch 82/100\n",
      "1571/1571 [==============================] - 31s 20ms/step - loss: 1.3624 - accuracy: 0.6930\n",
      "Epoch 83/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.3532 - accuracy: 0.6951\n",
      "Epoch 84/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.3446 - accuracy: 0.6964\n",
      "Epoch 85/100\n",
      "1571/1571 [==============================] - 31s 19ms/step - loss: 1.3367 - accuracy: 0.6992\n",
      "Epoch 86/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.3298 - accuracy: 0.6998\n",
      "Epoch 87/100\n",
      "1571/1571 [==============================] - 33s 21ms/step - loss: 1.3207 - accuracy: 0.7017\n",
      "Epoch 88/100\n",
      "1571/1571 [==============================] - 32s 21ms/step - loss: 1.3119 - accuracy: 0.7026\n",
      "Epoch 89/100\n",
      "1571/1571 [==============================] - 33s 21ms/step - loss: 1.3062 - accuracy: 0.7039\n",
      "Epoch 90/100\n",
      "1571/1571 [==============================] - 32s 20ms/step - loss: 1.2978 - accuracy: 0.7061\n",
      "Epoch 91/100\n",
      "1571/1571 [==============================] - 40s 26ms/step - loss: 1.2918 - accuracy: 0.7071\n",
      "Epoch 92/100\n",
      "1571/1571 [==============================] - 37s 23ms/step - loss: 1.2836 - accuracy: 0.7091\n",
      "Epoch 93/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 1.2753 - accuracy: 0.7101\n",
      "Epoch 94/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 1.2709 - accuracy: 0.7107\n",
      "Epoch 95/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.2648 - accuracy: 0.7124\n",
      "Epoch 96/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 1.2566 - accuracy: 0.7138\n",
      "Epoch 97/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.2506 - accuracy: 0.7154\n",
      "Epoch 98/100\n",
      "1571/1571 [==============================] - 34s 22ms/step - loss: 1.2447 - accuracy: 0.7171\n",
      "Epoch 99/100\n",
      "1571/1571 [==============================] - 35s 22ms/step - loss: 1.2395 - accuracy: 0.7170\n",
      "Epoch 100/100\n",
      "1571/1571 [==============================] - 36s 23ms/step - loss: 1.2318 - accuracy: 0.7185\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    model.fit(X, y, batch_size=128, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "yfL90sY6nCqz"
   },
   "outputs": [],
   "source": [
    "model.save(\"next_word_lstm_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "jGJqJxYMP_ZJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "def predict_next_word(model, input_words, word2idx, idx2word, seq_length):\n",
    "    # Convert words to their corresponding indices\n",
    "    input_seq = [word2idx.get(w.lower(), 0) for w in input_words]\n",
    "\n",
    "    # Pad the sequence to the required input length\n",
    "    input_seq = pad_sequences([input_seq], maxlen=seq_length)\n",
    "\n",
    "    # Predict next word\n",
    "    pred = model.predict(input_seq, verbose=0)\n",
    "    pred_idx = np.argmax(pred, axis=-1)[0]\n",
    "\n",
    "    # Return the predicted word\n",
    "    return idx2word.get(pred_idx, \"<unk>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "NuRWJXINRTO7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'doing'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"how\", \"are\", \"you\"], word2idx, idx2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'promise'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"i\", \"love\", \"you\"], word2idx, idx2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mistake'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"where\", \"is\", \"she\"], word2idx, idx2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fault'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"what\", \"is\", \"your\"], word2idx, idx2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"do\", \"you\", \"want\"], word2idx, idx2word, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2EhYH-LpRXUE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"i\", \"want\", \"to\", \"go\", \"with\"], word2idx, idx2word, seq_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "i-eMYbgZ5TKG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"can\", \"you\", \"help\", \"me\", \"with\"], word2idx, idx2word, seq_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"do\", \"you\", \"know\", \"what\", \"is\"], word2idx, idx2word, seq_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sight'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"let\", \"us\", \"meet\", \"at\", \"the\"], word2idx, idx2word, seq_length=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"i\", \"will\", \"see\"], word2idx, idx2word, seq_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'that'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_word(model, [\"how\", \"much\", \"does\"], word2idx, idx2word, seq_length=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: how are you doing today fuck you you cant walk away in the world did you ever turn around with me happy any good father dont make me laugh that was my fault hes in my way oh jesus why bother we are now are already serious you have to do this i brung you a little basket of goodies fresh squash tomatoes some okra butter beans dont make it less true i already tossed that out somethin you shoulda done to me its okay lets go to fight in the end of families ill catch you up ill see him when we get there nobody knows anything about that one if you were on your way it happened with the confession i know its thinking of the first rate and we share with their money you know you didnt come to me nothing matt ill invite him some name yes sir i had to turn on to her this room am in his funeral used and look at debbies inside mind thats what they do oh yes yes i know you found a note in the victims no last right away and this time is right sir at the base office the adventure ive been working on my future man once and he doesnt look forward for it in paris so pick tomorrow the things were like that and already as much of them like mine are you in mind this morning i just want you to meet him on the department thats not empty on your girl not you scared me in that family i think youd be better off for david everybody knows about it used to him did you that makes sense go out why do you do listen please yes guess lets go to burn well make you matthew make the picture one day your area is very dan for you to me funny more when be doing it youre only gonna be thinkin about it immediately i gotta get back before you almost got it now and the slow business from my honor and long a couple of money and a boy not anything else in business the little cow is that cousin possible friend please i want a ride time for you i think i could have a game if im givin jim you know you havent blew yourself in front days but garys not just another question of friends bob and you went in here tonight handle you can have us the damn is it it was any most of those things would i just hate off what is that youre in a hurry if you dont have to give me my gun mary down to you dorothy mozart though theyll be a little more issue last week you know the soul one and the president with ten other crime than all six years papa didnt work you think this is the guy that picked up you could date laugh just another job because i found you\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "# Load model\n",
    "model = load_model('next_word_lstm_model2.h5')\n",
    "\n",
    "\n",
    "def predict_next_words(seed_text, n_words, seq_len=5):\n",
    "    result = seed_text.split()\n",
    "    \n",
    "    for _ in range(n_words):\n",
    "        # Get last 'seq_len' words\n",
    "        input_seq = result[-seq_len:]\n",
    "        \n",
    "        # Convert to integer sequence\n",
    "        token_seq = [word2idx.get(w, 0) for w in input_seq]\n",
    "        token_seq = pad_sequences([token_seq], maxlen=seq_len)\n",
    "        \n",
    "        # Predict next word\n",
    "        predicted_idx = np.argmax(model.predict(token_seq, verbose=0), axis=-1)[0]\n",
    "        predicted_word = idx2word.get(predicted_idx, '')\n",
    "        \n",
    "        result.append(predicted_word)\n",
    "    \n",
    "    return ' '.join(result)\n",
    "with tf.device('/GPU:0'):\n",
    "    seed = \"how are you doing today\"\n",
    "    generated_text = predict_next_words(seed, n_words=500)\n",
    "    print(\"Generated:\", generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
